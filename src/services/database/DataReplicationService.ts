import { supabase } from '@/integrations/supabase/client';
import { enhancedSupabaseService } from './EnhancedSupabaseService';

export interface ReplicationConfiguration {
  id: string;
  user_id: string;
  name: string;
  description?: string;
  source_database: {
    type: 'supabase' | 'postgres' | 'mysql' | 'sqlite';
    connection_string: string;
    database_name: string;
  };
  target_database: {
    type: 'supabase' | 'postgres' | 'mysql' | 'sqlite';
    connection_string: string;
    database_name: string;
  };
  replication_type: 'master_slave' | 'master_master' | 'snapshot' | 'streaming';
  replication_mode: 'real_time' | 'batch' | 'scheduled';
  tables_to_replicate: string[];
  conflict_resolution: 'source_wins' | 'target_wins' | 'timestamp_wins' | 'manual';
  is_active: boolean;
  created_at: Date;
  updated_at: Date;
}

export interface ReplicationJob {
  id: string;
  configuration_id: string;
  job_type: 'initial_sync' | 'incremental_sync' | 'full_sync';
  status: 'queued' | 'running' | 'completed' | 'failed' | 'paused';
  started_at: Date;
  completed_at?: Date;
  records_processed: number;
  records_failed: number;
  tables_synced: string[];
  error_message?: string;
  sync_metadata: {
    last_sync_timestamp: Date;
    sync_direction: 'source_to_target' | 'target_to_source' | 'bidirectional';
    conflicts_detected: number;
    conflicts_resolved: number;
  };
}

export interface ReplicationMetrics {
  total_replications: number;
  active_replications: number;
  successful_syncs: number;
  failed_syncs: number;
  average_sync_time: number;
  data_lag: number;
  replication_health: 'healthy' | 'warning' | 'critical';
  last_sync_date: Date;
  total_records_replicated: number;
}

export class DataReplicationService {
  private static instance: DataReplicationService;
  private activeReplications: Map<string, NodeJS.Timeout> = new Map();

  private constructor() {}

  public static getInstance(): DataReplicationService {
    if (!DataReplicationService.instance) {
      DataReplicationService.instance = new DataReplicationService();
    }
    return DataReplicationService.instance;
  }

  // Replication Configuration Management
  async createReplicationConfiguration(config: Omit<ReplicationConfiguration, 'id' | 'created_at' | 'updated_at'>): Promise<ReplicationConfiguration> {
    try {
      console.log(`üîÑ Creating replication configuration: ${config.name}`);

      const { data, error } = await supabase
        .from('replication_configurations')
        .insert({
          user_id: config.user_id,
          name: config.name,
          description: config.description,
          source_database: config.source_database,
          target_database: config.target_database,
          replication_type: config.replication_type,
          replication_mode: config.replication_mode,
          tables_to_replicate: config.tables_to_replicate,
          conflict_resolution: config.conflict_resolution,
          is_active: config.is_active,
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString()
        })
        .select()
        .single();

      if (error) throw error;

      if (config.is_active) {
        await this.startReplication(data.id);
      }

      console.log(`‚úÖ Replication configuration created: ${config.name}`);
      return data;

    } catch (error) {
      console.error('‚ùå Failed to create replication configuration:', error);
      throw error;
    }
  }

  async startReplication(configurationId: string): Promise<void> {
    try {
      console.log(`üöÄ Starting replication: ${configurationId}`);

      const { data: config, error } = await supabase
        .from('replication_configurations')
        .select('*')
        .eq('id', configurationId)
        .single();

      if (error) throw error;

      // Perform initial sync if needed
      const hasInitialSync = await this.hasInitialSync(configurationId);
      if (!hasInitialSync) {
        await this.performInitialSync(configurationId);
      }

      // Start continuous replication
      switch (config.replication_mode) {
        case 'real_time':
          await this.startRealTimeReplication(configurationId);
          break;
        case 'batch':
          await this.startBatchReplication(configurationId);
          break;
        case 'scheduled':
          await this.startScheduledReplication(configurationId);
          break;
      }

      console.log(`‚úÖ Replication started: ${configurationId}`);

    } catch (error) {
      console.error('‚ùå Failed to start replication:', error);
      throw error;
    }
  }

  private async hasInitialSync(configurationId: string): Promise<boolean> {
    const { data, error } = await supabase
      .from('replication_jobs')
      .select('id')
      .eq('configuration_id', configurationId)
      .eq('job_type', 'initial_sync')
      .eq('status', 'completed')
      .limit(1);

    return !error && data && data.length > 0;
  }

  private async performInitialSync(configurationId: string): Promise<ReplicationJob> {
    try {
      console.log(`üîÑ Performing initial sync: ${configurationId}`);

      const { data: job, error } = await supabase
        .from('replication_jobs')
        .insert({
          configuration_id: configurationId,
          job_type: 'initial_sync',
          status: 'queued',
          started_at: new Date().toISOString(),
          records_processed: 0,
          records_failed: 0,
          tables_synced: [],
          sync_metadata: {
            last_sync_timestamp: new Date().toISOString(),
            sync_direction: 'source_to_target',
            conflicts_detected: 0,
            conflicts_resolved: 0
          }
        })
        .select()
        .single();

      if (error) throw error;

      this.executeInitialSync(job.id).catch(error => {
        console.error(`Initial sync ${job.id} failed:`, error);
      });

      return job;

    } catch (error) {
      console.error('‚ùå Failed to perform initial sync:', error);
      throw error;
    }
  }

  private async executeInitialSync(jobId: string): Promise<void> {
    try {
      await supabase
        .from('replication_jobs')
        .update({ status: 'running' })
        .eq('id', jobId);

      // Mock sync execution
      await new Promise(resolve => setTimeout(resolve, 2000));

      await supabase
        .from('replication_jobs')
        .update({
          status: 'completed',
          completed_at: new Date().toISOString(),
          records_processed: 1000,
          records_failed: 0,
          tables_synced: ['contacts', 'deals'],
        })
        .eq('id', jobId);

      console.log(`‚úÖ Initial sync completed: ${jobId}`);

    } catch (error) {
      console.error(`‚ùå Initial sync failed: ${jobId}`, error);

      await supabase
        .from('replication_jobs')
        .update({
          status: 'failed',
          completed_at: new Date().toISOString(),
          error_message: error.toString()
        })
        .eq('id', jobId);
    }
  }

  private async startRealTimeReplication(configurationId: string): Promise<void> {
    console.log(`‚ö° Starting real-time replication: ${configurationId}`);

    const interval = setInterval(async () => {
      try {
        await this.performIncrementalSync(configurationId);
      } catch (error) {
        console.error(`Real-time sync failed for ${configurationId}:`, error);
      }
    }, 5000);

    this.activeReplications.set(configurationId, interval);
  }

  private async startBatchReplication(configurationId: string): Promise<void> {
    console.log(`üì¶ Starting batch replication: ${configurationId}`);

    const interval = setInterval(async () => {
      try {
        await this.performIncrementalSync(configurationId);
      } catch (error) {
        console.error(`Batch sync failed for ${configurationId}:`, error);
      }
    }, 60000);

    this.activeReplications.set(configurationId, interval);
  }

  private async startScheduledReplication(configurationId: string): Promise<void> {
    console.log(`‚è∞ Starting scheduled replication: ${configurationId}`);

    const interval = setInterval(async () => {
      try {
        await this.performIncrementalSync(configurationId);
      } catch (error) {
        console.error(`Scheduled sync failed for ${configurationId}:`, error);
      }
    }, 3600000);

    this.activeReplications.set(configurationId, interval);
  }

  private async performIncrementalSync(configurationId: string): Promise<void> {
    try {
      const { data: job, error } = await supabase
        .from('replication_jobs')
        .insert({
          configuration_id: configurationId,
          job_type: 'incremental_sync',
          status: 'running',
          started_at: new Date().toISOString(),
          records_processed: 0,
          records_failed: 0,
          tables_synced: [],
          sync_metadata: {
            last_sync_timestamp: new Date().toISOString(),
            sync_direction: 'source_to_target',
            conflicts_detected: 0,
            conflicts_resolved: 0
          }
        })
        .select()
        .single();

      if (error) throw error;

      // Mock incremental sync
      const recordsToSync = Math.floor(Math.random() * 10);
      
      await supabase
        .from('replication_jobs')
        .update({
          status: 'completed',
          completed_at: new Date().toISOString(),
          records_processed: recordsToSync,
          records_failed: 0,
          tables_synced: recordsToSync > 0 ? ['contacts'] : []
        })
        .eq('id', job.id);

    } catch (error) {
      console.error('Failed to perform incremental sync:', error);
    }
  }

  async stopReplication(configurationId: string): Promise<void> {
    try {
      console.log(`‚èπÔ∏è Stopping replication: ${configurationId}`);

      const interval = this.activeReplications.get(configurationId);
      if (interval) {
        clearInterval(interval);
        this.activeReplications.delete(configurationId);
      }

      await supabase
        .from('replication_configurations')
        .update({ is_active: false })
        .eq('id', configurationId);

      console.log(`‚úÖ Replication stopped: ${configurationId}`);

    } catch (error) {
      console.error('‚ùå Failed to stop replication:', error);
      throw error;
    }
  }

  async getReplicationMetrics(userId: string): Promise<ReplicationMetrics> {
    try {
      const { data: configs, error: configError } = await supabase
        .from('replication_configurations')
        .select('id, is_active')
        .eq('user_id', userId);

      if (configError) throw configError;

      const { data: jobs, error: jobError } = await supabase
        .from('replication_jobs')
        .select('status, started_at, completed_at, records_processed')
        .in('configuration_id', (configs || []).map(c => c.id));

      if (jobError) throw jobError;

      const totalReplications = configs?.length || 0;
      const activeReplications = configs?.filter(c => c.is_active).length || 0;
      const successfulSyncs = jobs?.filter(j => j.status === 'completed').length || 0;
      const failedSyncs = jobs?.filter(j => j.status === 'failed').length || 0;

      return {
        total_replications: totalReplications,
        active_replications: activeReplications,
        successful_syncs: successfulSyncs,
        failed_syncs: failedSyncs,
        average_sync_time: 5,
        data_lag: Math.floor(Math.random() * 60),
        replication_health: 'healthy',
        last_sync_date: new Date(),
        total_records_replicated: jobs?.reduce((sum, job) => sum + (job.records_processed || 0), 0) || 0
      };

    } catch (error) {
      console.error('‚ùå Failed to get replication metrics:', error);
      throw error;
    }
  }
}

// Export singleton instance
export const dataReplicationService = DataReplicationService.getInstance();